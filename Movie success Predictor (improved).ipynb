{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:06:47) [MSC v.1914 32 bit (Intel)]\n",
      "scipy: 1.5.1\n",
      "numpy: 1.19.0\n",
      "matplotlib: 3.3.0\n",
      "pandas: 1.0.5\n",
      "sklearn: 0.23.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('Python: {}'.format(sys.version))\n",
    "# scipy\n",
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "# numpy\n",
    "import numpy\n",
    "print('numpy: {}'.format(numpy.__version__))\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "# pandas\n",
    "import pandas\n",
    "print('pandas: {}'.format(pandas.__version__))\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "from pandas import read_csv\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#If there are any errors, stop. Now is the time to fix them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Film  Genre  Year  Rotten Tomatoes %  Profit  class\n",
      "0     1      1  2008                 64   41.94      1\n",
      "1     2      2  2010                 68   19.62      0\n",
      "2     3      2  2010                 43   26.66      0\n",
      "3     4      2  2010                 15   43.04      0\n",
      "4     5      2  2008                 28  219.37      0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Genre\n",
       "1    15\n",
       "2    43\n",
       "3    13\n",
       "4     4\n",
       "5     1\n",
       "6     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "dataframe = pd.read_csv(r'\\Users\\abhih\\Downloads\\movie.csv')\n",
    "print(dataframe.head())\n",
    "dataframe.groupby(\"Genre\").size()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.   64.   41.94]\n"
     ]
    }
   ],
   "source": [
    "array = dataframe.values\n",
    "np.delete(array,1,axis=1)\n",
    "#print(array[:, 2])\n",
    "# separate array into input and output components\n",
    "X = array[:,1:5]\n",
    "Y= array[:, 5]\n",
    "# We'll check whether including the year improves results later\n",
    "# hence to traiing sets Xt and X\n",
    "X_with_year=X\n",
    "X=np.delete(X,1,axis=1)\n",
    "#dataframe.values\n",
    "print(X[0])\n",
    "#print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.40, random_state =30)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE WILL TRAIN ON SEVERAL MODELS TO FIND THE BEST MATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 0.8387096774193549\n",
      "LDA 0.9032258064516129\n",
      "KNN 0.7741935483870968\n",
      "CART 0.8709677419354839\n",
      "NB 0.9032258064516129\n",
      "SVM 0.6129032258064516\n"
     ]
    }
   ],
   "source": [
    "for name,model in models: \n",
    "    \n",
    "    model.fit(X_train, Y_train) \n",
    "    predictions=model.predict(X_test) \n",
    "    \n",
    "    print(name, accuracy_score(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear discriminant analysis works best for this set. \n",
    "Now we'll check raccuracy using release year as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_with_year, Y, test_size=0.40, random_state =30)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR 0.9032258064516129\n",
      "LDA 0.9032258064516129\n",
      "KNN 0.7741935483870968\n",
      "CART 0.8709677419354839\n",
      "NB 0.9032258064516129\n",
      "SVM 0.6129032258064516\n"
     ]
    }
   ],
   "source": [
    "for name,model in models: \n",
    "    \n",
    "    model.fit(X_train, Y_train) \n",
    "    predictions=model.predict(X_test) \n",
    "    \n",
    "    print(name, accuracy_score(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA still tops but the accuracy has fallen across it whie increasing in Linear regresion model. IN this case it seems release year is not significant so we will ignore it. \n",
    "Lets create a function for this model that we can call."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.40, random_state =30)  \n",
    "model=LinearDiscriminantAnalysis()\n",
    "model.fit(X_train, Y_train) \n",
    "\n",
    "#model.predict([[ 1,   64,   41.94]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict() :\n",
    " \n",
    "    v1=float(input(\"\\n1.Horror\\n2.Comedy\\n3.Thriller\\n4.Romcom\\n5.History\\n6.Documentary\\nEnter the Serial number of Genre:\"))\n",
    "    v2=float(input(\"Enter rating:\"))\n",
    "    v3=float(input(\"Enter profit:\"))\n",
    "    \n",
    "    databit=[]\n",
    "    databit.extend([v1,v2,v3])\n",
    "    datainsert=[databit]\n",
    "    \n",
    "    prediction=model.predict(datainsert)[0]\n",
    "    \n",
    "    if prediction==1:\n",
    "        print(\"HIT!\")\n",
    "    else:\n",
    "        print(\"FLOP!\")\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.Horror\n",
      "2.Comedy\n",
      "3.Thriller\n",
      "4.Romcom\n",
      "5.History\n",
      "6.Documentary\n",
      "Enter the Serial number of Genre:2\n",
      "enter rating12\n",
      "enter profit12\n",
      "FLOP!\n"
     ]
    }
   ],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
